KNN is one of the simplest supervised ML algorithms which utilizes the idea of “feature similarity” to predict the class of a certain data sample. It identifies a sample based on its neighbors by calculating its distance from the neighbors. In the KNN algorithm, the parameter _k_ affects the performance of the model. If the value of _k_ is very smaller, the model may be susceptible to over-fitting. While, a very large selection of _k_ value may result in misclassification of the sample instance.[61](https://onlinelibrary.wiley.com/doi/full/10.1002/ett.4150#ett4150-bib-0061), [62](https://onlinelibrary.wiley.com/doi/full/10.1002/ett.4150#ett4150-bib-0062) Karatas et al[63](https://onlinelibrary.wiley.com/doi/full/10.1002/ett.4150#ett4150-bib-0063) compared the performance of different ML algorithms using an up-to-date benchmark dataset CSE-CIC-IDS2018. They addressed the dataset imbalance problem by reducing the imbalance ratio using Synthetic Minority Oversampling Technique (SMOTE),[64](https://onlinelibrary.wiley.com/doi/full/10.1002/ett.4150#ett4150-bib-0064) which resulted in detection rate improvement for minority class attacks.